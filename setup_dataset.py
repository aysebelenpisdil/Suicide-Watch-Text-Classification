import os
import zipfile
import pandas as pd
from pathlib import Path

def setup_kaggle_credentials():
    kaggle_dir = Path.home() / '.kaggle'
    kaggle_json = kaggle_dir / 'kaggle.json'
    if not kaggle_json.exists():
        print("\nâš ï¸  Kaggle API anahtarÄ± bulunamadÄ±!")
        print("\nKaggle API anahtarÄ±nÄ± ayarlamak iÃ§in:")
        print("1. https://www.kaggle.com/account adresine gidin")
        print("2. 'Create New API Token' butonuna tÄ±klayÄ±n")
        print("3. Ä°ndirilen kaggle.json dosyasÄ±nÄ± ~/.kaggle/ klasÃ¶rÃ¼ne koyun")
        print("4. chmod 600 ~/.kaggle/kaggle.json komutunu Ã§alÄ±ÅŸtÄ±rÄ±n (Linux/Mac)")
        return False
    return True

def download_dataset():
    if not setup_kaggle_credentials():
        return False
    try:
        import kaggle
        print("\nğŸ“¥ Veri seti indiriliyor...")
        kaggle.api.dataset_download_files(
            'nikhileswarkomati/suicide-watch',
            path='data/raw',
            unzip=True
        )
        print("âœ… Veri seti baÅŸarÄ±yla indirildi!")
        return True
    except Exception as e:
        print(f"âŒ Hata: {e}")
        print("\nAlternatif olarak:")
        print("1. https://www.kaggle.com/datasets/nikhileswarkomati/suicide-watch adresine gidin")
        print("2. 'Download' butonuna tÄ±klayÄ±n")
        print("3. Ä°ndirilen CSV dosyasÄ±nÄ± data/raw/ klasÃ¶rÃ¼ne koyun")
        return False

def check_dataset():
    dataset_path = Path('data/raw/Suicide_Detection.csv')
    if not dataset_path.exists():
        print("\nâš ï¸  Veri seti dosyasÄ± bulunamadÄ±!")
        print(f"Beklenen konum: {dataset_path.absolute()}")
        return False
    print("\nğŸ“Š Veri seti bilgileri:")
    df = pd.read_csv(dataset_path)
    print(f"- Toplam Ã¶rnek sayÄ±sÄ±: {len(df):,}")
    print(f"- SÃ¼tunlar: {', '.join(df.columns)}")
    print(f"\n- SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:")
    class_counts = df['class'].value_counts()
    for class_name, count in class_counts.items():
        label = "Non-suicide" if class_name == 0 else "Suicide"
        print(f"  {label} (class={class_name}): {count:,} ({count/len(df)*100:.1f}%)")
    print(f"\n- Ä°lk 3 Ã¶rnek:")
    for i in range(min(3, len(df))):
        text = df.iloc[i]['text'][:100] + "..." if len(df.iloc[i]['text']) > 100 else df.iloc[i]['text']
        print(f"  {i+1}. Class={df.iloc[i]['class']}: {text}")
    return True

def main():
    print("=" * 60)
    print("SUICIDE WATCH VERÄ° SETÄ° KURULUM")
    print("=" * 60)
    data_dirs = ['data/raw', 'data/processed', 'data/splits']
    for dir_path in data_dirs:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
    if not check_dataset():
        if download_dataset():
            check_dataset()
        else:
            print("\nâŒ Veri seti indirilemedi. LÃ¼tfen manuel olarak indirin.")
            return
    print("\nâœ… Veri seti hazÄ±r!")
    print("\nSonraki adÄ±mlar:")
    print("1. notebooks/01_veri_analizi.ipynb ile veri keÅŸfi yapÄ±n")
    print("2. src/data_preprocessing.py ile veri Ã¶n iÅŸleme yapÄ±n")
    print("3. Model eÄŸitimi iÃ§in notebooks/03_model_egitim.ipynb kullanÄ±n")

if __name__ == "__main__":
    main()